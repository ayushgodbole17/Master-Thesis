import re
import torch
import pandas as pd
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from nltk.translate.bleu_score import sentence_bleu
from rouge import Rouge

# Configuration for paths (replace with your actual paths or environment variables)
MODEL_LYRICS_DIR = "path_to_fine_tuned_gpt2_lyrics"
MODEL_MELODY_DIR = "path_to_fine_tuned_gpt2_melody"
REFERENCE_FILE_PATH = "path_to_clean_lyrics.txt"
CSV_FILE_PATH = "path_to_final_melody_data.csv"

# Load models and tokenizers
tokenizer_lyrics = GPT2Tokenizer.from_pretrained(MODEL_LYRICS_DIR)
model_lyrics = GPT2LMHeadModel.from_pretrained(MODEL_LYRICS_DIR, use_safetensors=True)
model_lyrics.eval()

tokenizer_melody = GPT2Tokenizer.from_pretrained(MODEL_MELODY_DIR)
model_melody = GPT2LMHeadModel.from_pretrained(MODEL_MELODY_DIR, use_safetensors=True)
model_melody.eval()

def find_reference_text(prompt, generated_text_length, reference_file):
    with open(reference_file, 'r', encoding='utf-8') as file:
        reference_text = file.read()
    
    match = re.search(re.escape(prompt), reference_text, re.IGNORECASE)
    if match:
        start_idx = match.start()
        end_idx = start_idx + generated_text_length
        return reference_text[start_idx:end_idx]
    else:
        print("Prompt not found in the reference text.")
        return None

def generate_lyrics(model_lyrics, tokenizer_lyrics, prompt, max_length=100, num_return_sequences=1):
    inputs = tokenizer_lyrics(prompt, return_tensors="pt").to(model_lyrics.device)
    
    outputs = model_lyrics.generate(
        input_ids=inputs.input_ids,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        pad_token_id=tokenizer_lyrics.pad_token_id,
        repetition_penalty=1.5,
        do_sample=True,
        top_k=30,
        top_p=0.5
    )
    
    generated_texts = [tokenizer_lyrics.decode(output, skip_special_tokens=True) for output in outputs]
    return generated_texts

def evaluate_lyrics(generated_text, reference_text):
    reference_tokens = [reference_text.split()]
    candidate_tokens = generated_text.split()
    
    bleu_score = sentence_bleu(reference_tokens, candidate_tokens)
    print(f"BLEU Score: {bleu_score}")

    rouge = Rouge()
    rouge_scores = rouge.get_scores(generated_text, reference_text)
    print(f"ROUGE Scores: {rouge_scores}")

    return bleu_score, rouge_scores

def calculate_perplexity(model, tokenizer, text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(model.device)
    with torch.no_grad():
        outputs = model(**inputs, labels=inputs["input_ids"])
        loss = outputs.loss
    perplexity = torch.exp(loss).item()
    return perplexity

def preprocess_lyrics_for_melody(generated_text):
    generated_text = generated_text.lower()
    generated_text = re.sub(r'[^a-z\s]', '', generated_text)
    generated_text = re.sub(r'\s+', ' ', generated_text).strip()
    return generated_text

def generate_melody(model_melody, tokenizer_melody, generated_text, config, note_token="<NOTE>"):
    preprocessed_text = preprocess_lyrics_for_melody(generated_text)
    words = preprocessed_text.split()
    num_words = len(words)

    inputs = tokenizer_melody(preprocessed_text, return_tensors="pt").to(model_melody.device)

    outputs = model_melody.generate(
        input_ids=inputs.input_ids,
        max_new_tokens=num_words * 3,
        num_return_sequences=1,
        pad_token_id=tokenizer_melody.pad_token_id,
        repetition_penalty=config['repetition_penalty'],
        do_sample=True,
        top_k=config['top_k'],
        top_p=config['top_p']
    )

    generated_melody_raw = tokenizer_melody.decode(outputs[0], skip_special_tokens=True)
    generated_melody_tokens = generated_melody_raw.split()

    generated_notes = [token for token in generated_melody_tokens if token.startswith(note_token)]

    if len(generated_notes) == 0:
        print("No notes were generated by the model.")
        return "No melody generated"

    if len(generated_notes) < num_words:
        generated_notes = (generated_notes * (num_words // len(generated_notes) + 1))[:num_words]

    final_melody = ' '.join(generated_notes)
    return final_melody

def extract_reference_melody(reference_text, csv_file):
    df = pd.read_csv(csv_file)
    words = [word.strip().lower() for word in reference_text.split()]
    reference_melody = []
    word_idx = 0

    for i in range(len(df)):
        word = str(df['Word'].iloc[i]).strip().lower()
        note = df['Note'].iloc[i]
        
        if word_idx < len(words) and word == words[word_idx]:
            if pd.notna(note) and note.lower() != "rest":
                reference_melody.append(note)
            word_idx += 1
        
        if word_idx >= len(words):
            break
    
    final_melody = ' '.join(reference_melody)
    return final_melody

# Define parameter combinations for experimentation
configs = [
    {'repetition_penalty': 1.2, 'top_k': 100, 'top_p': 0.95},
    {'repetition_penalty': 1.5, 'top_k': 50, 'top_p': 0.9},
    {'repetition_penalty': 2.0, 'top_k': 20, 'top_p': 0.8},
]

# Define the prompt variable
prompt = "Lose yourself in the music"

# Generate lyrics
generated_texts = generate_lyrics(model_lyrics, tokenizer_lyrics, prompt, max_length=50, num_return_sequences=1)
generated_text = generated_texts[0]

for i, text in enumerate(generated_texts):
    print(f"Generated Text {i + 1}:\n{text}\n")

# Find the reference text that matches the prompt and is the same length as the generated text
reference_text = find_reference_text(prompt, len(generated_text), REFERENCE_FILE_PATH)
print(f"Reference Text:\n{reference_text}\n")

if reference_text:
    bleu_score, rouge_scores = evaluate_lyrics(generated_text, reference_text)
    perplexity = calculate_perplexity(model_lyrics, tokenizer_lyrics, generated_text)
    print(f"Perplexity: {perplexity}")
else:
    print("No suitable reference text found for evaluation.")

# Run experiments with different parameter combinations
results = []
for i, config in enumerate(configs):
    print(f"\n### Experiment {i+1} with Config: {config} ###")
    
    generated_melody = generate_melody(model_melody, tokenizer_melody, generated_text, config)
    print(f"Generated Melody:\n{generated_melody}\n")

    reference_melody = extract_reference_melody(reference_text, CSV_FILE_PATH)
    print(f"Reference Melody:\n{reference_melody}\n")

    if reference_melody:
        bleu_score, rouge_scores = evaluate_lyrics(generated_melody, reference_melody)
        melody_perplexity = calculate_perplexity(model_melody, tokenizer_melody, generated_melody)
        results.append({
            'config': config,
            'bleu_score': bleu_score,
            'rouge_scores': rouge_scores,
            'perplexity': melody_perplexity
        })

# Compare results
for i, result in enumerate(results):
    print(f"\nExperiment {i+1} Results (Config: {result['config']}):")
    print(f"BLEU Score: {result['bleu_score']}")
    print(f"ROUGE Scores: {result['rouge_scores']}")
    print(f"Melody Perplexity: {result['perplexity']}")